{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c517bb91-f740-d62a-0781-4f1ad64a1478",
    "_uuid": "9f67a0975b8adc4cfa31e307b929467ff62fcf2c"
   },
   "source": [
    "# From image files to Numpy Arrays!\n",
    "Since we can't work directly with the data here in Kaggle (because it has more than 1k files), this notebook assumes it is in a \"/src\" folder and you're working with the data decompressed in a \"/data/all\" folder.    \n",
    "\n",
    "Download the data and work with it directly in your machine! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "eab6b702-5c09-044e-b3a9-01c5d7944250",
    "_uuid": "76291f3169abdbad43d36966e4d7f93225aee29a"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "1803c9ed-b3a1-9e8e-7e7f-1cc866a14ee6",
    "_uuid": "302160e61a8deb32332a8d01d6f3734000b03f26"
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from IPython.display import display\n",
    "from IPython.display import Image as _Imgdis\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from time import time\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "5847c2c8-b489-184d-05c5-11743ccf6c15",
    "_uuid": "4e3cfe0c5e023dee5a853a0ea92285d8daa8b960"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/regression_sample'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7786d18390fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../input/regression_sample\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0monlyfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Working with {0} images\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monlyfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/regression_sample'"
     ]
    }
   ],
   "source": [
    "folder = \"../input/regression_sample\"\n",
    "\n",
    "onlyfiles = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n",
    "\n",
    "print(\"Working with {0} images\".format(len(onlyfiles)))\n",
    "print(\"Image examples: \")\n",
    "\n",
    "for i in range(40, 42):\n",
    "    print(onlyfiles[i])\n",
    "    display(_Imgdis(filename=folder + \"/\" + onlyfiles[i], width=240, height=320))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "84088914-97aa-1720-08bd-6a587b5f52b6",
    "_uuid": "19a4cd7376e601b69cc31efa185a89b4a5a9c64a"
   },
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "train_files = []\n",
    "y_train = []\n",
    "i=0\n",
    "for _file in onlyfiles:\n",
    "    train_files.append(_file)\n",
    "    label_in_file = _file.find(\"_\")\n",
    "    y_train.append(int(_file[0:label_in_file]))\n",
    "    \n",
    "print(\"Files in train_files: %d\" % len(train_files))\n",
    "\n",
    "# Original Dimensions\n",
    "image_width = 640\n",
    "image_height = 480\n",
    "ratio = 4\n",
    "\n",
    "image_width = int(image_width / ratio)\n",
    "image_height = int(image_height / ratio)\n",
    "\n",
    "channels = 3\n",
    "nb_classes = 1\n",
    "\n",
    "dataset = np.ndarray(shape=(len(train_files), channels, image_height, image_width),\n",
    "                     dtype=np.float32)\n",
    "\n",
    "i = 0\n",
    "for _file in train_files:\n",
    "    img = load_img(folder + \"/\" + _file)  # this is a PIL image\n",
    "    img.thumbnail((image_width, image_height))\n",
    "    # Convert to Numpy Array\n",
    "    x = img_to_array(img)  \n",
    "    x = x.reshape((3, 120, 160))\n",
    "    # Normalize\n",
    "    x = (x - 128.0) / 128.0\n",
    "    dataset[i] = x\n",
    "    i += 1\n",
    "    if i % 250 == 0:\n",
    "        print(\"%d images to array\" % i)\n",
    "print(\"All images to array!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b667d7d7-c9a3-933e-0223-e279176d3684",
    "_uuid": "b5081c79afb593e8cc278b0bfc36fcb2cd67df7f"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Splitting \n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset, y_train, test_size=0.2, random_state=33)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=33)\n",
    "print(\"Train set size: {0}, Val set size: {1}, Test set size: {2}\".format(len(X_train), len(X_val), len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2a1041db-9821-6319-ebb2-510b0ed8b3aa",
    "_uuid": "14df3fb8af9084e0b6b037d014c64edfed4fd76e"
   },
   "source": [
    "### Use your favorite model! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "df646e72-a3ef-0871-63df-e50826531af2",
    "_uuid": "93a7da29ae7cd62c68ffb5a409fac9b2af8cf08c"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
